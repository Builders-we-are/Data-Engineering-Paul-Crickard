# Data-Engineering-Paul-Crickard

 # Data Engineering with Python â€“ Companion Repository

A handsâ€‘on project repo that follows Data Engineering with Python by Paul Crickard (2ndâ€¯ed.).  Each chapter is translated into reproducible code, datasets, and unitâ€‘tested pipelines so you can learn by doing and build a portfolio piece at the same time.

---

 What Youâ€™ll Find Here

| Folder              | Chapter | Theme                       | Deliverable                                  |
| ------------------- | ------- | --------------------------- | -------------------------------------------- |
| `01_extract/`       | 1â€‘2     | Extract, APIs, Web Scraping | Python scripts + RAW data snapshots          |
| `02_transform/`     | 3â€‘5     | Cleaning, Pandas, PySpark   | Jupyter notebooks + pytestâ€‘backed transforms |
| `03_load/`          | 6       | Loading to Postgres, S3     | SQL DDL + bulkâ€‘loader helpers                |
| `04_orchestration/` | 7â€‘8     | Airflow DAGs, Scheduling    | Dockerâ€‘Compose Airflow stack, unit DAG tests |
| `05_streaming/`     | 9       | Kafka, Realâ€‘time ETL        | Dockerized Kafka connect + Stream demo       |
| `06_visualization/` | 10      | Dashboards                  | Superset charts + Grafana panels             |
| `infra/`            | â€”       | Terraform IaC               | Localâ€‘stack + AWS option                     |
| `tests/`            | â€”       | Pytest testâ€‘suite           | 90%+ coverage target                         |

Each folder is selfâ€‘containedâ€”open the README inside a subâ€‘folder to dive into just that piece.



---

## ğŸ›   Quickâ€‘Start (Local Docker Compose)

1. Clone & bootstrap

   ```bash
   git clone https://github.com/yourâ€‘handle/dataâ€‘engâ€‘withâ€‘python.git
   cd dataâ€‘engâ€‘withâ€‘python
   make init          # sets up .env & preâ€‘commit hooks
   make composeâ€‘up    # spins Postgres, Kafka, Airflow, Superset
   ```
2. **Run pipelines**

   ```bash
   make runâ€‘extract   # scrapes + drops raw JSON in /data/raw
   make runâ€‘airflow   # triggers DAGs to transform & load
   ```
3. Explore

   * Airflow UI 
   * Superset 
   * pgAdmin



---

## â˜ï¸  Deploying to AWS (Optional)

```bash
cd infra/aws
terraform init && terraform apply
```

Creates:

* VPC with Publicâ€“Private subnets
* RDS Postgres, MSKâ€‘Kafka, MWAAâ€‘Airflow
* S3 bucket for raw & processed layers
  
#TODO by Ade
See `infra/README.md` for teardown & costâ€‘saving tips.

---

## ğŸ§ª Testing & Quality

* Linters â€“ `ruff`, `black`, `mypy`
* Tests â€“ `pytest` + coverage report (`make test`)
* CI â€“ GitHub Actions workflow (`.github/workflows/ci.yml`)

---

Contributing

Spotted a bug or have an idea? Open an **issue** or submit a **PR**. Please follow the conventional commit style and ensure `make test` passes.

---

ğŸ“„ License

Apacheâ€‘2.0.  Feel free to fork and adapt for your own learning!

---
 ğŸ”— References

* Paul Crickard â€“ *Data Engineering with Python*, Oâ€™Reilly, 2ndâ€¯ed., 2023.
* Official repo: [https://github.com/PacktPublishing/Dataâ€‘Engineeringâ€‘Withâ€‘Pythonâ€‘Secondâ€‘Edition](https://github.com/PacktPublishing/Dataâ€‘Engineeringâ€‘Withâ€‘Pythonâ€‘Secondâ€‘Edition)
